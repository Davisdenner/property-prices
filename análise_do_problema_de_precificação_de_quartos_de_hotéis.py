# -*- coding: utf-8 -*-
"""Análise do problema de precificação de quartos de hotéis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19WIZz17B2npqBGiO-rGWeE4PclMKsugk

# A tarefa envolve conduzir as seguintes etapas:

Análise inicial com o Seaborn;
construir modelos de regressão linear; e
realizar a comparação desses modelos.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dados = pd.read_csv('/content/hoteis.csv')

dados.count()

dados.info()

dados.head()

"""# Correlação

Quais fatores estão relacionados ao preço dos hoteis? Como é essa relação?

Com o coeficiente de Correlação de Pearson nos permite medir a relação linear entre variáveis, oferecendo uma escala que varia de -1 a 1, que interpretamos conforme sua intensidade e direção:

* -1: indica uma correlação negativa perfeita: à medida que uma variável aumenta, a outra diminui.
* 0: não há relação linear entre as variáveis.
* 1: correlação positiva perfeita: à medida que uma variável aumenta, a outra também aumenta.
"""

corr = dados.corr()
corr

corr['Preco']

# Quais fatores estão mais correlacionados?

# Gerar uma máscara para o triângulo superior
mascara = np.zeros_like(corr, dtype=bool)
mascara[np.triu_indices_from(mascara)] = True

# Configurar a figura do matplotlib
f, ax = plt.subplots(figsize=(11, 9))

# Gerar o mapa de calor (heatmap)
cmap = sns.diverging_palette(220, 10, as_cmap=True)

sns.heatmap(corr, mask=mascara, cmap=cmap, vmax=1, vmin=-1, center=0,
            square=True, linewidths=.5, annot=True, cbar_kws={"shrink": .5})

# Exibir o mapa de calor (heatmap)
plt.show()

# importando as visualizações

import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns

dados.columns

# Como é a relação entre capacidade e preço?
plt.scatter(dados['ProximidadeTurismo'], dados['Preco'])
plt.title('Relação entre Proximidade do Turismo e preço')
plt.xlabel('ProximidadeTurismo')
plt.ylabel('Preco')
plt.show()

# Qual a reta que melhor se adequa a relação?
px.scatter(dados, x = 'ProximidadeTurismo', y = 'Preco', trendline_color_override="red", trendline = 'ols' )

"""### Separando em treino e teste

O conjunto de **treinamento** é usado para ajustar o modelo, enquanto o conjunto de **teste** é usado para avaliar seu desempenho em prever preços dos hoteis não vistos durante o treinamento, que auxilia na generalização do modelo.
"""

# import train_test_split
from sklearn.model_selection import train_test_split

# Definindo y e X

y = dados['Preco']
X = dados.drop(columns = 'Preco')

#Aplicando o split do y e X
train_test_split(X, y, test_size = 0.3, random_state= 230)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state= 230)

#Dados de treino para usar a fórmula

df_train = pd.DataFrame(data= X_train)
df_train['Preco'] = y_train

# import ols
from statsmodels.formula.api import ols

# ajustando o primeiro modelo
modelo_0 = ols('Preco ~ProximidadeTurismo', data = df_train).fit()

# visualizando os parametros
modelo_0.params

# o resumo do nosso modelo
print(modelo_0.summary())

""" O R² varia de 0 a 1, onde 1 indica um ajuste perfeito do modelo aos dados, ou seja, todas as variações na variável dependente são explicadas pelas variáveis independentes no modelo. Por outro lado, um R² de 0 indica que o modelo não explica nenhuma variabilidade na variável dependente"""

# observando o R²
modelo_0.rsquared

# definindo o Y previsto
y_predict = modelo_0.predict(X_test)

# importando o r2_score
from sklearn.metrics import r2_score

# printando o r²
print("R²: ", r2_score(y_test,y_predict))

"""## Analisando os fatores"""

# quais outras características poderiam explicar o preço das diárias dos hoteis?
sns.pairplot(dados)

#Vamos olhar apenas com y_vars='preco_de_venda'
sns.pairplot(dados, y_vars = 'Preco', x_vars = ['Estrelas','Capacidade', 'ProximidadeTurismo'])

"""## Adicionando fatores no modelo"""

# importando a api do statsmodels
import statsmodels.api as sm

# adicionando o constante
X_train = sm.add_constant(X_train)

X_train.head()

dados.columns

# Criando o modelo de regressão (sem fómula): saturado
modelo_1 = sm.OLS(y_train,
                  X_train[['Estrelas', 'ProximidadeTurismo', 'Capacidade']]).fit()

# Modelo sem as informações sobre a Capacidade
modelo_2 =  sm.OLS(y_train,
                  X_train[['Estrelas', 'ProximidadeTurismo']]).fit()

# Modelo sem as informações sobre as estrelas
modelo_3 = sm.OLS(y_train,
                  X_train[['ProximidadeTurismo']]).fit()

"""## Comparando modelos"""

print("R²")
print("Modelo 0: ", modelo_0.rsquared)
print("Modelo 1: ", modelo_1.rsquared)
print("Modelo 2: ", modelo_2.rsquared)
print("Modelo 3: ", modelo_3.rsquared)

#Quantos parametros estão no modelo?
print(len(modelo_0.params))
print(len(modelo_1.params))
print(len(modelo_2.params))
print(len(modelo_3.params))

# Resumo do modelo 0
print(modelo_0.summary())

# Resumo do modelo 1
print(modelo_1.summary())

"""#  Comparando os 2 modelos:

R-squared e Adjusted R-squared: O primeiro modelo tem valores mais altos, indicando que explica melhor a variabilidade dos dados.

AIC e BIC: O primeiro modelo tem valores mais altos, o que pode penalizar a complexidade do modelo, mas ainda assim, a diferença não é tão significativa comparada à melhoria em explicação.

O RMSE do primeiro modelo é menor, indicando melhor precisão nas previsões.
Durbin-Watson: Ambos os modelos têm valores próximos de 2, o que sugere uma ausência de autocorrelação significativa nos resíduos.

Portanto, essas métricas proporcionarão uma compreensão mais completa e equilibrada da performance do seu modelo. Qual escolher dependerá do objetivo, o segundo modelo é mais simples e pode ser preferível em contextos onde a simplicidade e interpretabilidade são mais importantes. O primeiro modelo sugere que ele é mais robusto.
"""

